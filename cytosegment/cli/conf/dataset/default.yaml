type: png
path: data/all_naiad_zmd_320_80.zip
#  data_path: dataset/training_testing_set_w_beads_and_enrichment.zip
# "min_max" = True: minimum and maximum pixel values of each image will be
# used to normalize the dataset. Otherwise, 255 will be used to divide each
# and every image in the dataset
img_size:
  - 80
  - 320
augmentation: True
valid_size: 0.15
batch_size: 8

# Mean and std values for the whole dataset should be computed before
# starting the training using 'unet/dataset_utils/compute_mean_std.py'
# script. The computed values can be used during the model inference.
# If there is a change in the dataset (either inclusion or exclusion of
# image and mask pairs into the dataset), we need to recalculate the mean
# and std values of the dataset again.

# Mean and std values for enriched dataset - with beads
#  mean: 0.498
#  std: 0.086

# Mean and std values for enriched dataset - without beads
#  mean: 0.487
#  std: 0.084

# Mean and std values of Naiad dataset
mean: 0.519
std: 0.072

random_seed: 42
# how many subprocesses to use for dataset loading. 0 means that the dataset
# will be loaded in the main process.
num_workers: 8