hydra:
  run:
    dir: ${path_out}/${now:%d%b%y}_${now:%H-%M-%S}_singlerun
  sweep:
    # Output dir path
    dir: ${path_out}/${now:%d%b%y}_${now:%H-%M-%S}_multirun
    # Run dir path (with )
    subdir: ${hydra.job.override_dirname}
  job:
    config:
      override_dirname:
        exclude_keys:
          - slurm

# Model configuration =========================================================
model:
  type: TunableUNet
  in_channels: 1
  out_classes: 1
  # Options: either 'single' or 'double'
  conv_block: double
  # Model depth
  depth: 2
  # Options: 1 to n (2**n)
  filters: 3
  # Options: 1 (no dilation), 2, 3, 4
  dilation: 1
  batch_norm: True
  # Options: in the range of 0.1, 0.9
  dropout: 0
  # Options: 'upconv', 'upsample'
  up_mode: upconv
  attention: False
  relu: True
  # Options: 'normal', 'xavier', 'HeNormal', 'HeUniform', 'orthogonal'
  weight_init: HeNormal

# Data configuration =========================================================
data:
  type: png
  path: data/all_naiad_zmd_320_80.zip
  #  path: dataset/training_testing_set_w_beads_and_enrichment.zip

  # Normalize input images with min-max pixel values
  min_max: True
  img_size:
    - 80
    - 320
  augmentation: True
  valid_size: 0.15
  batch_size: 8

  # Mean and std values for enriched dataset - with beads
  #  mean: 0.498
  #  std: 0.086

  # Mean and std values for enriched dataset - without beads
  #  mean: 0.487
  #  std: 0.084

  # Mean and std values of Naiad dataset
  mean: 0.519
  std: 0.072

  random_seed: 42

  # Number of workers for data loading
  num_workers: 8

# Trainer configuration =======================================================
train:
  criterion:
    type: FocalTverskyLoss
    alpha: 0.5
    gamma: 1.5

  metric:
    type: DiceCoeff

  optimizer:
    type: Adam
    learn_rate: 0.01

  scheduler:
    type: ReduceLROnPlateau
    patience: 10
    lr_decay_rate: 0.5

# HPC parameters =============================================================
hpc_params:
  mail_id: raghava.alajangi@mpl.mpg.de
  max_mem_GB: 10
  max_time_hours: 00:30:00  # hh:mm:ss

# Misc parameters =============================================================
# Submit jobs to SLURM cluster
slurm: false

path_out: experiments

max_epochs: 1

use_cuda: True

# Save model weights if 'val_acc' is greater than 'min_ckp_acc'
min_ckp_acc: 0.80

# Stop training if 'val_acc' doesn't improve for 'early_stop_patience' epochs
early_stop_patience: 15

# Resume training from this checkpoint
init_from_ckp: null

# Use TensorBoard for tracking
tensorboard: False
